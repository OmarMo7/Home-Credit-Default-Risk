{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Encountered Obstacles\n","- Selecting features\n","- The need to a massive amount of RAM capacity to merge the csv files into\n","- I am thinking of applying the feature selection only on df_application_train, the rest of features in the other csv files are to be selected manually.\n","- As there are too many csv files and all of them contain too many records, I have decided to apply feature selection only on df_application_train, manually select some features from the rest of files, and finally merge everything into each other. \n","- My goal is to merge all the columns of all dataframes with the \"TARGET\" column exsiting in df_application_train and apply the correlation matrix to find `indepenedently` how \"TARGET\" is influenced by the features of this table alone\n","- The df_application_train was chosen to be primary as it the only df that conatins the column 'TARGET'\n","- To go about the data accurately, clinically, and methodically I decided that the best way to select should be through the confussion matrix insteat of my presonal judgment.\n","- After i have applied the feature selection methods of mine and generated totally new dataframes: df_train and df_test, it turns out there was no real difference between them and the original train and test dataframes. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T20:05:58.041044Z","iopub.status.busy":"2024-09-06T20:05:58.040381Z","iopub.status.idle":"2024-09-06T20:05:58.045804Z","shell.execute_reply":"2024-09-06T20:05:58.044729Z","shell.execute_reply.started":"2024-09-06T20:05:58.041001Z"},"trusted":true},"outputs":[],"source":["# !pip install pandas matplotlib -q\n","# !pip install numpy -q\n","# !pip install dask[dataframe] -q\n","# !pip install \"dask[diagnostics]\" -qprint(df)print(df)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:43:12.698456Z","iopub.status.busy":"2024-09-07T18:43:12.697329Z","iopub.status.idle":"2024-09-07T18:43:15.303529Z","shell.execute_reply":"2024-09-07T18:43:15.302360Z","shell.execute_reply.started":"2024-09-07T18:43:12.698403Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:43:15.307010Z","iopub.status.busy":"2024-09-07T18:43:15.305891Z","iopub.status.idle":"2024-09-07T18:44:57.515371Z","shell.execute_reply":"2024-09-07T18:44:57.514064Z","shell.execute_reply.started":"2024-09-07T18:43:15.306950Z"},"trusted":true},"outputs":[],"source":["# df_description = pd.read_csv(\"./data/HomeCredit_columns_description.csv\")\n","# df_sample_submission = pd.read_csv(\"/kaggle/input/home-credit-default-risk/home-credit-default-risk/sample_submission.csv\")\n","df_application_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk/home-credit-default-risk/application_train.csv\")\n","df_bureau_balance = pd.read_csv(\"/kaggle/input/home-credit-default-risk/bureau_balance.csv\")\n","df_bureau = pd.read_csv(\"/kaggle/input/home-credit-default-risk/bureau.csv\")\n","df_credit_card_balance = pd.read_csv(\"/kaggle/input/home-credit-default-risk/credit_card_balance.csv\")\n","df_installments_payments = pd.read_csv(\"/kaggle/input/home-credit-default-risk/installments_payments.csv\")\n","df_POS_CASH_balance = pd.read_csv(\"/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\")\n","df_previous_application = pd.read_csv(\"/kaggle/input/home-credit-default-risk/previous_application.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:44:57.517270Z","iopub.status.busy":"2024-09-07T18:44:57.516743Z","iopub.status.idle":"2024-09-07T18:44:58.639590Z","shell.execute_reply":"2024-09-07T18:44:58.638435Z","shell.execute_reply.started":"2024-09-07T18:44:57.517228Z"},"trusted":true},"outputs":[],"source":["df_application_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk/home-credit-default-risk/application_test.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:44:58.642897Z","iopub.status.busy":"2024-09-07T18:44:58.642464Z","iopub.status.idle":"2024-09-07T18:45:22.253719Z","shell.execute_reply":"2024-09-07T18:45:22.252360Z","shell.execute_reply.started":"2024-09-07T18:44:58.642835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(304531, 159)\n"]}],"source":["# Drop columns with all NaN values\n","df_application_train = df_application_train.dropna(axis=1, how='all')\n","    \n","# Drop columns with more than 95% NaN values\n","threshold = len(df_application_train) * 0.95\n","df_application_train = df_application_train.dropna(axis=1, thresh=threshold)\n","    \n","# Drop NaN values\n","df_application_train = df_application_train.dropna()\n","        \n","# One-hot encode categorical variables\n","df_application_train = pd.get_dummies(df_application_train)\n","\n","# Calculate the correlation matrix\n","corr_matrix = df_application_train.corr()\n","    \n","# Get the absolute correlation values with the target variable\n","important_features = corr_matrix['TARGET'].abs().sort_values(ascending=False)\n","    \n","# Filter features with relevance value higher than 0.08\n","selected_features = important_features[important_features > 0.03]\n","\n","selected_feature_names = selected_features.index.tolist()\n","\n","selected_feature_names.append(\"SK_ID_CURR\")\n","        \n","# Create a new dataframe with the selected features\n","df_application_train_selected_features = df_application_train[selected_feature_names]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.255558Z","iopub.status.busy":"2024-09-07T18:45:22.255171Z","iopub.status.idle":"2024-09-07T18:45:22.266059Z","shell.execute_reply":"2024-09-07T18:45:22.264403Z","shell.execute_reply.started":"2024-09-07T18:45:22.255517Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(304531, 28)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_application_train_selected_features.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.268557Z","iopub.status.busy":"2024-09-07T18:45:22.268069Z","iopub.status.idle":"2024-09-07T18:45:22.281067Z","shell.execute_reply":"2024-09-07T18:45:22.279454Z","shell.execute_reply.started":"2024-09-07T18:45:22.268508Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(304531, 159)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_application_train.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.282952Z","iopub.status.busy":"2024-09-07T18:45:22.282535Z","iopub.status.idle":"2024-09-07T18:45:22.650369Z","shell.execute_reply":"2024-09-07T18:45:22.649098Z","shell.execute_reply.started":"2024-09-07T18:45:22.282883Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(47772, 27)\n"]}],"source":["# Drop columns with all NaN values\n","df_application_test = df_application_test.dropna(axis=1, how='all')\n","    \n","# Drop columns with more than 95% NaN values\n","threshold = len(df_application_test) * 0.95\n","df_application_test = df_application_test.dropna(axis=1, thresh=threshold)\n","    \n","# Drop NaN values\n","df_application_test = df_application_test.dropna()\n","        \n","# One-hot encode categorical variables\n","df_application_test = pd.get_dummies(df_application_test)\n","\n","selected_feature_names.remove(\"TARGET\")\n","\n","df_application_test_selected_features = df_application_test[selected_feature_names]\n","\n","print(df_application_test_selected_features.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.652045Z","iopub.status.busy":"2024-09-07T18:45:22.651644Z","iopub.status.idle":"2024-09-07T18:45:22.658519Z","shell.execute_reply":"2024-09-07T18:45:22.657146Z","shell.execute_reply.started":"2024-09-07T18:45:22.652004Z"},"trusted":true},"outputs":[],"source":["# List of dataframes to process\n","dataframes = [\n","    df_bureau,\n","    df_bureau_balance,\n","    df_credit_card_balance,\n","    df_installments_payments,\n","    df_POS_CASH_balance,\n","    df_previous_application,\n","]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.660490Z","iopub.status.busy":"2024-09-07T18:45:22.660114Z","iopub.status.idle":"2024-09-07T18:45:22.675354Z","shell.execute_reply":"2024-09-07T18:45:22.673882Z","shell.execute_reply.started":"2024-09-07T18:45:22.660453Z"},"trusted":true},"outputs":[],"source":["def process_dataframe_train(df, merged_df):\n","    # Check if 'SK_ID_CURR' column exists in the dataframe\n","    if 'SK_ID_CURR' not in df.columns:\n","        return merged_df\n","    \n","    # Drop columns with all NaN values\n","    df = df.dropna(axis=1, how='all')\n","    \n","    # Drop columns with more than 95% NaN values\n","    threshold = len(df) * 0.95\n","    df = df.dropna(axis=1, thresh=threshold)\n","    \n","    # Drop NaN values\n","    df = df.dropna()\n","    \n","    df = df.drop_duplicates(subset=['SK_ID_CURR'])\n","        \n","    # One-hot encode categorical variables\n","    df = pd.get_dummies(df)\n","    \n","    df = pd.merge(df, df_application_train_selected_features[['SK_ID_CURR', 'TARGET']], on='SK_ID_CURR', how='left')\n","    \n","    # Calculate the correlation matrix\n","    corr_matrix = df.corr()\n","    \n","    # Get the absolute correlation values with the target variable\n","    important_features = corr_matrix['TARGET'].abs().sort_values(ascending=False)\n","    \n","    # Filter features with relevance value higher than 0.03\n","    selected_features = important_features[important_features > 0.06]\n","        \n","    # Extract the feature names\n","    selected_feature_names = selected_features.index.tolist()\n","    \n","    # Ensure 'SK_ID_CURR' is included in the selected features\n","    if 'SK_ID_CURR' not in selected_feature_names:\n","        selected_feature_names.append('SK_ID_CURR')\n","        \n","    selected_feature_names.remove(\"TARGET\")\n","    selected_feature_names = list(set(selected_feature_names))\n","        \n","    # Create a new dataframe with the selected features\n","    df_selected_features = df[selected_feature_names]\n","    \n","    # Merge with the existing merged_df on 'SK_ID_CURR'\n","    merged_df = pd.merge(merged_df, df_selected_features, on='SK_ID_CURR', how='left')\n","    \n","    return merged_df"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.680247Z","iopub.status.busy":"2024-09-07T18:45:22.679611Z","iopub.status.idle":"2024-09-07T18:45:22.692246Z","shell.execute_reply":"2024-09-07T18:45:22.690977Z","shell.execute_reply.started":"2024-09-07T18:45:22.680200Z"},"trusted":true},"outputs":[],"source":["def process_dataframe_test(df, merged_df, df_train):\n","    # Check if 'SK_ID_CURR' column exists in the dataframe\n","    if 'SK_ID_CURR' not in df.columns:\n","        return merged_df\n","    \n","    # Drop columns with all NaN values\n","    df = df.dropna(axis=1, how='all')\n","    \n","    # Drop columns with more than 95% NaN values\n","    threshold = len(df) * 0.95\n","    df = df.dropna(axis=1, thresh=threshold)\n","    \n","    # Drop NaN values\n","    df = df.dropna()\n","    \n","    df = df.drop_duplicates(subset=['SK_ID_CURR'])\n","        \n","    # One-hot encode categorical variables\n","    df = pd.get_dummies(df)\n","    \n","    selected_feature_names = df_train.columns.tolist()\n","    \n","    # Ensure 'SK_ID_CURR' is included in the selected features\n","    if 'SK_ID_CURR' not in selected_feature_names:\n","        selected_feature_names.append('SK_ID_CURR')\n","        \n","    selected_feature_names.remove(\"TARGET\")\n","    selected_feature_names = list(set(selected_feature_names))\n","    \n","    intersection_columns = list(set(df.columns) & set(selected_feature_names))\n","        \n","    # Create a new dataframe with the selected features\n","    df_selected_features = df[selected_feature_names]\n","    \n","    # Merge with the existing merged_df on 'SK_ID_CURR'\n","    merged_df = pd.merge(merged_df, df_selected_features, on='SK_ID_CURR', how='left')\n","    \n","    return df"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:45:22.693987Z","iopub.status.busy":"2024-09-07T18:45:22.693549Z","iopub.status.idle":"2024-09-07T18:46:05.608756Z","shell.execute_reply":"2024-09-07T18:46:05.607586Z","shell.execute_reply.started":"2024-09-07T18:45:22.693946Z"},"trusted":true},"outputs":[],"source":["# Initialize the merged dataframe with df_application_train_not_na_onehot\n","df_train = df_application_train_selected_features.copy()\n","\n","# Process each dataframe and merge\n","for df in dataframes:\n","    df_train = process_dataframe_train(df, df_train)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:47:43.486270Z","iopub.status.busy":"2024-09-07T18:47:43.485233Z","iopub.status.idle":"2024-09-07T18:47:43.495238Z","shell.execute_reply":"2024-09-07T18:47:43.493480Z","shell.execute_reply.started":"2024-09-07T18:47:43.486223Z"},"trusted":true},"outputs":[{"data":{"text/plain":["33"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(df_train.columns)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:46:05.623555Z","iopub.status.busy":"2024-09-07T18:46:05.622739Z","iopub.status.idle":"2024-09-07T18:46:48.179938Z","shell.execute_reply":"2024-09-07T18:46:48.178889Z","shell.execute_reply.started":"2024-09-07T18:46:05.623498Z"},"trusted":true},"outputs":[],"source":["# Initialize the merged dataframe with df_application_train_not_na_onehot\n","df_test = df_application_test_selected_features.copy()\n","\n","# Process each dataframe and merge\n","for df in dataframes:\n","    df_test = process_dataframe_test(df, df_test, df_application_train)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-07T18:47:35.499849Z","iopub.status.busy":"2024-09-07T18:47:35.499339Z","iopub.status.idle":"2024-09-07T18:47:35.508518Z","shell.execute_reply":"2024-09-07T18:47:35.506799Z","shell.execute_reply.started":"2024-09-07T18:47:35.499804Z"},"trusted":true},"outputs":[{"data":{"text/plain":["32"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(df_test.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2602785,"sourceId":4445793,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
